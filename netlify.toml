[build]
  publish = "dist"
  command = "npm run build"

[[redirects]]
  from = "/*"
  to = "/index.html"
  status = 200

# Remove restrictive headers that block crawlers
[[headers]]
  for = "/*"
  [headers.values]
    X-Frame-Options = "SAMEORIGIN"
    X-Content-Type-Options = "nosniff"
    Referrer-Policy = "strict-origin-when-cross-origin"
    # Removed X-XSS-Protection as it's deprecated
    # Relaxed CSP to allow crawlers
    Content-Security-Policy = "default-src 'self' https:; script-src 'self' 'unsafe-inline' 'unsafe-eval' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' https:; connect-src 'self' https:; frame-ancestors 'self';"

# Specific headers for robots.txt to ensure it's accessible
[[headers]]
  for = "/robots.txt"
  [headers.values]
    Content-Type = "text/plain"
    Cache-Control = "public, max-age=86400"

# Specific headers for sitemap.xml
[[headers]]
  for = "/sitemap.xml"
  [headers.values]
    Content-Type = "application/xml"
    Cache-Control = "public, max-age=86400"

# Allow all crawlers access to static assets
[[headers]]
  for = "/static/*"
  [headers.values]
    Cache-Control = "public, max-age=31536000"

# Ensure proper headers for main pages
[[headers]]
  for = "/home"
  [headers.values]
    Cache-Control = "public, max-age=3600"

[[headers]]
  for = "/about"
  [headers.values]
    Cache-Control = "public, max-age=3600"

[[headers]]
  for = "/contact"
  [headers.values]
    Cache-Control = "public, max-age=3600"

[[headers]]
  for = "/privacy"
  [headers.values]
    Cache-Control = "public, max-age=3600"